## Проверка статистических гипотез

**Статистическая гипотеза** – утверждение о свойствах распределения вероятностей случайной величины (или случайного вектора).

+ Гипотеза нуждается в проверке.
+ Проверка основывается на результатах эксперимента, на наблюдениях.

Что значит доказать, что вакцина работает? Randomized double blind placebo control studies
Делим людей на две группы: одна с вакциной, другая - без. Затем будем сравнивать, насколько ситуация хуже у тех, кто находится в контрольной группе, т.е. не вакцинирован.
Те, кто не вакцинирован, им все равно что-то колят. И они не знают, что это не вакцина. И те, кто колят, тоже не знаю вакцина это или нет. 
A/B тест. В данном случае, A - с вакциной, B - контрольная

Что сравниваем:

+ Доля участников с антителами
+ Процент заболевших
+ Тяжесть болезни (смертность)
+ После вакцины пытаемся заразить

#### Зачем проверяют статистические гипотезы

+ Обозначим функцию $F_X(t)$ распределения случайной величины $Х$.
+ Пусть $F_0(t)$ - некоторая заданная функция распределения.
+ **Гипотеза**: функции распределения совпадают, то есть $F_X(t) = F_0(t)$

1. Гипотеза согласия

+ Гипотеза о нормальности распределения. -> 1) Нормальное распределение часто встречается. Когда распределение нормальное, экономим деньги если: 
А) распределение можно считать нормальным и; Б) задана необходимая погрешность результата, то потребуется меньше наблюдений. Например, опросим меньше покупателей.
+ Гипотеза об экспоненциальности распределения. Часто описывает время ожидания.Например, время до аварии (нужно для расчета страховой премии;
время обслуживания покупателя кассиром (нужно для определения числа работающих касс в супермаркете);
время до поломки изделия (нужно для планирования расходов на гарантийныйремонт).

2. Гипотеза однородности

+ Обозначим $F_X(t)$ функцию распределения случайной величины $Х$.
+ Обозначим $F_Y(t)$ функцию распределения случайной величины $Y$
+ **Гипотеза**: функции распределения совпадают $F_X(t) = F_Y(t)$

Примеры: распределение продаж до рекламной акции и после нее. Если распределение продаж не изменилось, то улучшения нет.
Может сравниваться распределение покупателей по возрасту. Например, если реклама была нацелена на конкретный сегмент, например, на молодых мам.

3. Гипотеза независимости

**Гипотеза**: случайные величины $X$ и $Y$ независимы

Примеры: Если возраст покупателей и объем покупки зависимы, то возраст надо учитывать при сегментации покупателей.
Иногда зависимость бывает неочевидной. Длина волос и рост людей – зависимые переменные. (Женщины ниже и их волосы длиннее)

4. Гипотезы о параметре распределения

Чаще всего распределение случайной величины не важно. Важна лишь одна характеристика распределения.

+ Гипотеза. Математические ожидания случайных величин $X$ и $Y$ равны. $EX = EY$
+ Гипотеза: Медианы случайных величин $X$ и $Y$ равны. $Med(X) = Med(Y)$

#### Типичные значения(центры распределения)

Подмена задачи: Сравнение столбцов подменяем сравнением типичных значений. Остается решить, когда лучше сравнивать средние значения, а когда лучше сравнивать медианы.

### Основные условия применения статистических тестов

+ Вопрос должен касаться какой-либо характеристики массового явления.
+ Характеристика меняется случайным образом от наблюдения к наблюдению.
+ Вопрос должен быть относительно простым и четко сформулированным

**Не умеем! Гипотеза справедлива с вероятностью 0.86**

### Основная и альтернативная гипотезы

Основная гипотеза и Альтернативная (конкурирующая) гипотеза. Стандартное обозначение H0 и H1.
Если не уточняется, о какой гипотезе идет речь, то подразумевается основная гипотеза.
Чаще всего (но не всегда) одна гипотеза утверждает, что предположение верно, другая – что нет.

Разное отношение к основной и альтернативной гипотезам
Неточно говорить «…основная гипотеза принята…» или «…выбрана основная гипотеза…».

Правильно говорить «основная гипотеза отвергнута…» и «основная гипотеза не отвергнута…». Так как обычно проверяют лишь достаточное условие.

### Ошибки первого и второго рода

+ Ошибка первого рода совершается, если отвергается основная гипотеза, когда на самом деле она верна.
+ Ошибка второго рода совершается, если отвергается конкурирующая гипотеза, когда она верна.

### Уровень значимости $\alpha$

+ Уровень значимости ограничивает сверху долю ошибок первого рода.
+ Начиная с Фишера в качестве уровня значимости чаще всего используют 0.005, 0.01, 0.05.
+ Ожидается, что одна проверка из 200, 100, 20 будет давать неверный результат (на большой выборке).

### Состоятельный критерий. Когда ошибка второго рода мала?

+ Как добиться того, чтобы вероятность ошибки второго рода была малой?
+ Ошибку очень сложно вычислять.
+ Применяйте состоятельные критерии.
+ Ошибку можно уменьшить, если увеличить число анализируемых наблюдений.
+ Необходимы большие выборки.

### Ошибка второго рода и мощность критерия

Мощность = 1 — P{ошибка 2 рода}

+ Вместо минимизации вероятности ошибки 2 рода максимизируем мощность
+ Причины технические, так проще формулы

### Статистика критерия или тестовая статистикой

+ Статистика критерия или тестовая статистика, это функция от наблюдений, которая измеряет, насколько данные соответствуют гипотезе.
+ Изредка она важна в приложениях, например, коэффициент корреляции. В таких конкретных случаях мы будем ее обсуждать.
+ Статистика критерия необходима для обоснования статистического критерия.

### Алгоритм проверки статистических гипотез

1. Имеются n наблюдений , то есть n чисел, столбец в таблице данных.
2. Заранее задается уровень значимости $\alpha$. Обычно это одно из чисел 0.005, 0.01, 0.05.
3. Проверяются условия, при которых критерий можно применять. Условия – Из учебника или справочника.
4. Находится p-значение
5. Если $p < \alpha$ - основную гипотезу отвергаем, если $p > \alpha$ - основную гипотезу не отвергаем. При этом $\alpha$ – уровень значимости, $p$- p-value.

**Выбор того статистического критерия, который решает прикладную задачу – важная и сложная задача**

## Популярные статистические критерии

### 1) Гипотеза о нормальности распределения случайной величины

+ Гипотеза: Случайная величина имеет нормальное распределение, значения параметров распределения могут быть любыми.
+ Конкурирующая гипотеза: Распределение случайной величины отличается от нормального.

Критерий Шапиро-Уилка, Критерий Anderson-Darling, Критерий Lilliefors (Kolmogorov-Smirnov)

Рекоммендации: Если меньше 2000 (?) наблюдений, рекомендуется использовать критерий Шапиро-Уилка; если больше 2000 (?), то критерий Колмогорова-Смирнова.

А нужно ли проверять гипотезу нормальности?

Методы, которые рассматриваются в курсе далее, работают когда:

+ переменная имеет нормальное распределение
+ распределение несущественно отличается от нормального

Даже когда гипотеза о нормальности распределения переменной отвергнута. Некоторые отклонения от нормальности несущественные.

**Существенные отклонения**

1. Наличие выбросов в данных.
2. Явная асимметрия гистограммы.
3. Очень сильное отклонение формы гистограммы от колоколообразной формы.

**Рекомендуется относиться**

+ Строго - к присутствию выбросов,
+ Снисходительно - к отклонениям от симметрии.
+ Отношение к отклонениям от колоколообразности гистограммы зависит от числа наблюдений. Если меньше 30 наблюдений - в высшей степени либерально, если от 30 до 150 наблюдений - снисходительно, если больше 150 наблюдений – строго.

**Лекарства**

Иногда они опаснее болезни...
+ Выбросы — удаляем (осторожно!)
+ Асимметрия — преобразуем данные (например, логарифмируем, или преобразование Бокса- Кокса)
+ Бимодальность — разбиваем выборку на подвыборки

### 2) Гипотезы о типичных наблюдениях (о центрах распределений)

Сравнение центров распределений

Центр распределения - то одно единственное число, которое описывает, характеризует выборку.
+ В качестве центра чаще всего используют среднее арифметическое, медиану или усеченное среднее.
+ Центр распределения и типичное наблюдение синонимы

#### Среднее арифметическое или медиана?

+ Если распределение хотя бы одной выборки существенно отличается от нормального, в качестве центра предлагается использовать медиану.
+ В остальных случаях, то есть если распределение каждой выборки можно считать нормальным или несущественно отличающимся от нормального, в качестве центра предлагается использовать среднее арифметическое.

Если центр распределения медиана, используем критерий Манна–Уитни-Вилкоксона или (редко) Mood's median критерий.
Если центр распределения среднее арифметическое, используем одну из версий критерия Стьюдента.

**Прагматичный подход**:  Применить оба теста. Если выводы совпадают, ответ есть Если выводы различны, начинаем разбираться.

#### Парные выборки

+ В случае парных выборок имеются пары наблюдений (измерений) одного и того же объекта.
+ Например: пары измерений делались в один и тот же момент.
+ Например: два измерения одного показателя делались последовательно.

#### Независимые выборки

+ В случае независимых выборок каждое наблюдение соответствует отдельному объекту, измеряются разные объекты.

Принадлежность объектов выборкам определяется по значениям дополнительной группирующей переменной.

**1) средних значений выборок**

+ H0: EX = EY
+ H1: EX ≠ EY

Используем T-критерий Стьюдента

При сравнении средних важны дисперсии. Большое различие средних… Малое различие средних значений… Важно, одинаковы ли дисперсии

*Используем для сравнения дисперсии Fligner-Killeen test. Робастный, рекомендуется. возможно Brown-Forsythe test еще лучше...*

Если данные существенно отклоняются от нормальности, но нужно сравнить средние
1. Все как в случае нормальности, если выборка большая (n> 300)
2. Преобразовать данные к нормальному виду

**2) Сравнение медиан выборок**

+ H0: Медианы равны
+ H1: Медианы различаются

Критерий Манна-Уитни, Mood's median test

Важно!

+ Критерий Манна-Уитни на самом деле проверяет другую гипотезу.
+ Имеются две выборки наблюдений случайных величин Х и Y.

+ H0: P{X>Y}=P{X<Y}.
+ H1: P{X>Y} ≠ P{X<Y}.

Критерий Манна-Уитни не учитывает величины наблюдений, а только их ранги

### Еще раз, кратко

Если оба распределения несущественно отличаются от нормального, то используем критерий Стьюдента
Если сравниваем медианы, и много наблюдений , то используем критерий Муда
Если сравниваем медианы и распределения одинаковы по форме, то используем критерий Манна-Уитни
Если сравниваем медианы и распределения НЕ одинаковы по форме, иногда нельзя применять критерий Манна-Уитни,

x1 <- c( 1, 1, 1, 1000, 1000)
x2 <- c( 2, 3, 4, 5, 6)
Доходы x1 выше, x2 прибыльнее чаще

**3) Гипотеза независимости**

+ H0: Случайные величины X и Y независимы
+ H1: Случайные величины X и Y зависимы

На практике отвечаем на вопрос: переменная X влияет на переменную Y?

Если неизвестно, X влияет на Y или Y влияет на X, то статистический критерий не поможет!

#### Статистическая зависимость

+ **Определение.** Cтатистическая зависимость – это функциональная зависимость СРЕДНЕГО значения переменной y от значения переменной x.
+ Откуда появляется среднее значение? Проводятся эксперименты (или наблюдается явление) при одном и том же значении x, при этом регистрируются разные значения y, затем эти значения усредняются.
+ На практике не всегда заметно, что одному и тому же значению переменной x может соответствовать много значений y, например когда повторные наблюдения при одном значении x не делались.

Коэффициент корреляции как «градусник», измеряющий степень зависимости

#### Выбор коэффициента

+ Если распределение каждой переменной несущественно отличается от нормального, применяется коэффициент корреляции Пирсона
+ В остальных случаях - коэффициент корреляции Спирмена
+ Вместо коэффициента корреляции Спирмена используют коэффициент корреляции Кендалла

Зависимость -2

X – в количественной шкале; Y – в номинальной шкале. Сравниваем средние или медианы в группах. Или перекодируем количественную переменную, переводим ее в номинальную шкалу

Зависимость -3

X – в порядковой шкале; Y – в порядковой шкале. Используем коэффициент корреляции Спирмена или Кендалла

Зависимость -4

X – в номинальной шкале; Y – в номинальной шкале. Таблица сопряженности и критерий χ²

## Итог

+ Проверка гипотезы о нормальности распределения.

H0:  𝑋∼𝑁(⋅,⋅) 
H1:  𝑋≁𝑁(⋅,⋅)
 
+ Критерий Шапиро-Уилка scipy.stats.shapiro.

+ Критерий согласия Стьюдента.
H0:  𝜇=𝑀
H1:  𝜇≠𝑀
 
scipy.stats.ttest_1samp.

+ Проверка гипотезы о равенстве средних значений.

H0:  𝜇1=𝜇2
H1:  𝜇1≠𝜇2
 
Распределение выборок должно быть близко к нормальному.

* Для несвязных выборок: scipy.stats.ttest_ind.
* Для связных выборок: scipy.stats.ttest_rel.

+ Проверка гипотезы о равенстве медиан.

* Для несвязных выборок: критерий Манна-Уитни scipy.stats.mannwhitneyu.
* Для связных выборок: критерий Уилкоксона scipy.stats.wilcoxon.
* Критерий Муда scipy.stats.median_test.

+ Проверка гипотезы о равенстве дисперсий.

H0:  𝜎1=𝜎2
H1:  𝜎1≠𝜎2
 
Критерий Флингера-Килина scipy.stats.fligner.

+ Проверка гипотезы о равенстве долей категориального признака.

H0:  𝑝1=𝑝2
H1:  𝑝1≠𝑝2
 
Критерий хи-квадрат scipy.stats.chi2_contingency.

+ Проверка гипотезы о независимости (корреляция).

H0: X и Y независимы
H1: X и Y зависимы

* Для нормальных величин: корреляция Пирсона scipy.stats.pearsonr,
* Для переменных в ранговой шкале: корреляция Спирмэна scipy.stats.spearmanr.
* Для переменных в ранговой шкале: корреляция Кендалла scipy.stats.kendalltau.