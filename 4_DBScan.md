## DBScan

### Идея метода

Искать кластеры это искать области в пространстве

+ с высокой плотностью точек
+ связные, т.е. части кластера не могут быть далеко друг от друга

### Как измерять плотность точек

**Определение.** $\epsilon$ - окрестность точки $А$ — шар радиуса $\epsilon$ с центром в точке $А$

**Определение.** Плотность в окрестности точки $A$ равна числу точек в окрестности (в шаре), деленному на объем окрестности (шара).

Объем окрестности всегда один и тот же. Чтобы сравнивать плотности в разных точках, не обязательно делить на объем шара, радиус шара каждый раз один и тот же.

Считаем, что в шаре высокая плотность точек, если в него попало не менее $m$ точек.

### Основные параметры процедуры DBSCAN

Надо настраивать 2 параметра и выбрать расстояние.

$\epsilon$ Если расстояние между точками меньше $\epsilon$, точки считаются близкими

$m$ Если в окрестности точки m или больше точек, то эта точка находится в области, где точки расположены плотно, а плотно упакованная точками область это ядро кластера. В scikit-learn саму точку включают в подсчет.

Способ подсчета расстояний между точками формализует, что значит «похожи». Если три параметра заданы, то число кластеров определяется однозначно. Но состав кластеров может несущественно меняться.

Не спешите радоваться. Число кластеров определять не надо. Вместо определения числа кластеров надо определять ε и m. Это гораздо сложнее

### То же самое более строго 

точки $x$, $y$ и $z$ – наблюдения

$dist(x, y)$ – расстояние между точками $x$ и $y$

Константы $\epsilon$ и $m$ нужны, чтобы определить соседей, близкие объекты.

$\epsilon$ окрестность объекта $x$ это шар радиуса $\epsilon$ $E(x)=\left\{ y: dist(x , y) \leq \epsilon \right\}$
Точки из $\epsilon$ - окрестности объекта $x$ будем называть соседями точки $x$. Будем считать их близкими, похожими на $x$ точками

Другими словами, если $z \in E(x)$, то точки $x$ и $z$ соседи, если $x \in E(z)$ , то точки $x$ и $z$ соседи

Точки бывают трех классов: **корневые**, **граничные** и **выбросы**.Класс точки зависит от значений трех параметров.

**Корневым объектом или ядерным объектом степени $m$** называется объект $x$, $\epsilon$-окрестность которого содержит не менее $m$ объектов: $|E(x)| \geq m$.
Вокруг корневого объекта $x$ большая плотность точек. Корневые точки $x$ в ядре кластера

**Граничная точка** расположена на границе кластера, но обязательно включены в кластеры.

**Выбросы** - точки, которые не поали не в один кластер.

### Алгоритм кластеризации

1. Составим список объектов из первого кластера
2. Для этого выберем какой-нибудь корневой объект p из набора данных, начнем с него список объектов кластера.
3. Добавим в список всех его соседей.
4. Продолжим пополнять список объектов кластера. Для этого начнем перебирать объекты из списка. Если в ходе перебора встречаем корневую точку, добавляем всех её соседей в список обхода. Каждая точка входит в список один раз, повторений не допускаем.
5. Когда перебрали все объекты из списка, пополнение невозможно, все точки из списка составляют кластер.

Кодом -1 обозначаются наблюдения вне кластеров — шум, выбросы

Кластеризация зависит от порядка перебора точек?
Ответ: Результат однозначен для корневых точек и для выбросов. Граничные точки могут оказаться в разных кластерах.

### Комментарии

1. DBSCAN очень похож на обобщение иерархического кластерного анализа, когда расстояние между кластерами вычисляется методом ближайшего соседа. Вместо ближайшего соседа используется m–й ближайший сосед.
2. DBSCAN может выявлять ленточные кластеры.
3. DBSCAN плохо работает, когда шаровые скопления соединены перемычками.
4. DBSCAN плохо кластеризует наборы данных с большой разницей в плотности, так как у всех кластеров одна и та же пара параметров $m$ и $\epsilon$
5. DBSCAN выигрывает, когда у нас в данных присутствуют кластеры на фоне равномерно распределенного набора точек

### Подбор параметров

**Вариант 1**

Перебираем параметры на решетке. Сравниваем значения «силуэта». Недостаток метода. «силуэт» неприменим для измерения качества ленточных кластеров.

**Вариант 2**

$m$: Если $m = 2$ получаем иерархический кластерный анализ примененный с методом ближайшего соседа.

Несколько эмпирических правил:

+ $m >= 3$
+ $m >= D+1$, $D$ - число признаков
+ $m >= 2*D$
+ $m = ln(n)$

$\epsilon$:

Если $\epsilon$ выбрана слишком малыми, большая часть данных будет отнесена к выбросам, а для слишком больших значений $\epsilon$ кластеры будут сливаться и большинство объектов окажутся в одном кластере.

Значение $\epsilon$ может быть выбрано с помощью графика, похожего на каменистую осыпь. Упорядочиваем расстояния до m-го ближайшего соседа в возрастающем порядке. Искомое значение ε соответствует «излому» графика.

Обычно малые значения $\epsilon$ предпочтительнее.

**Расстояние:** Расстояние должно отражать наше представление о схожести объектов.