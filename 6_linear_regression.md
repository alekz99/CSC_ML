## Линейная регрессия

### Модель

Данные: пары чисел $\{x_i, y_i\}$

Гипотеза: имеется линейная статистическая зависимость между переменными $X$ и $Y$

$Y = a + b*X + \epsilon$

Надо найти оценки коэффициентов $a$ и $b$ уравнения регрессии: $Y = a + b*X$

Для поиска прямой, необходимо минимизировать сумму расстояний до этой прямой от каждой точки. Расстояния, параллельные вертикальной оси (красный цвет).

![Объекты](/images/lect_6/log_regr.png)

Значения $a$ и $b$ находятся по методу наименьших квадратов, т.е. так, чтобы минимизировать величину

$$MSE = \frac{1}{n}\sum_{i=1}^n (y_i - (a+b*x_i))^2 = \frac{1}{n}\sum_{i=1}^n (y_i - \widehat{y_i})^2$$

### Терминология

+ $Y$ — отклик / зависимая переменная
+ $Х$ — предиктор / независимая переменная
+ $\epsilon_i = y_i - (a + b\cdotx_i)$ - ошибка / невязка / погрешность
+ $\widehat{y_i} = a + b \cdot x_i$- модельное / теоретическое значение

Базовая модель. Сумма квадратов отклонений для базовой модели. Зависит от единиц измерения

### Коэффициент детерминации

$$R^2=1 - \frac{\frac{1}{n}\sum_{i=1}^n (y_i - (a+b \cdot x_i))^2}{\frac{1}{n}\sum_{i=1}^n (y_i - \widehat{y_n})^2}$$

1 - модель отлтчная, 0 - модель плохая. 

### Философия, которая продолжится в будущем

+ Семейство функций
+ Функции отличаются значениями параметров (параметрическое семейство функций)
+ Критерий качества
+ Параметры подбираются так, чтобы минимизировать/максимизировать критерий качества
+ Оценки параметров

**Недостатки множественного коэффициента детерминации**

Пример «Квартет Анскомба»

![Объекты](/images/lect_6/Anscombe_quartet.png)

+ Mean of x in each case 9
+ Sample variance of x in each case 11
+ Mean of y in each case 7.50
+ Sample variance of y in each case 4.122 or 4.127
+ Correlation between x and y in each case 0.816
+ Linear regression line in each case y = 3.00 + 0.500x

### Исходные предположения регрессионного анализа

$$y_i = \beta_0 + \beta_1 \cdot x_{1,i} + \beta_2 \cdot x_{2,i} + ... + \beta_k \cdot x_{k,i} + \epsilon_i, i=1...n$$

1. (Сферический конь в вакууме)
При заданных значениях переменных $x_j j=1, ..., k$ на отклик $y$ не оказывают влияние никакие другие предикторы. Влияние других предикторов учитывается случайной возмущающей переменной. При этом $\epsilon = 0$.
2. Гомоскедастичность. Дисперсия случайной переменной $\epsilon$ должна быть для всех
наблюдений одинакова и постоянна: $D \epsilon_i = const i=1...n$
3. Независимость ошибок. Значения случайной переменной ϵ попарно некоррелированы или, еще более сильная предпосылка, они попарно независимы: $corr(\epsilon_i, \epsilon_j) = 0, 	i,j = 1,...,n ,i ≠ j$
4. Таблица с данными не «плоская». Число наблюдений должно превышать число предикторов $n>k$
5. Объясняющие переменные X j не коррелируют с ошибкой $\epsilon$. $corr(X_i, \epsilon) = 0$
6 Нормальное распределение ошибок. Переменная $\epsilon$ нормально распределена.

Все обычно хорошо, если $\epsilon$ представляет собой суммарный эффект от большого числа незначительных некоррелированных влияющих на отклик переменных. Как следствие, отклик y распределен нормально.

Раньше было так. Сейчас делим выборку на тест и трейн и проверяем как работает. **Хороша та модель, которая работает на практике!**

![Объекты](/images/lect_6/now_use.png)


**Для выявления коллинеарности используем: tolerance или VIF.**
